import os
import warnings
import logging
import cv2
import time
import requests
import mediapipe as mp
import numpy as np
import threading
import speech_recognition as sr
from collections import deque
from flask import Flask, request, jsonify

# python-dotenv ì„¤ì¹˜ í™•ì¸ ë° ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("âš ï¸ python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install python-dotenvë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
    print("ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

# í™˜ê²½ ì„¤ì • ë° ê²½ê³  ì–µì œ
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['DISPLAY'] = ''
warnings.filterwarnings('ignore')
logging.getLogger('tensorflow').setLevel(logging.ERROR)
logging.getLogger('mediapipe').setLevel(logging.ERROR)
logging.getLogger('absl').setLevel(logging.ERROR)

class VoiceStopGestureRecognizer:
    def __init__(self):
        """
        HTTP ìŒì„± ì¤‘ì§€ ì‹ í˜¸ ì œìŠ¤ì²˜ ì¸ì‹ê¸°
        - left_hand: ìŒì„±ì¸ì‹ ë£¨í”„ ì‹œì‘ â†’ HTTP /voice-stop ì‹ í˜¸ë¡œ ì¢…ë£Œ
        - right_hand: ê±°ë¦¬ì¸¡ì • â†’ ì›¹ì„œë²„
        """
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„œë²„ ì„¤ì • ì½ê¸°[1]
        self.app_server_ip = os.getenv('APP_SERVER_IP', '192.168.1.100')
        self.web_server_ip = os.getenv('WEB_SERVER_IP', '192.168.1.101')
        self.app_server_port = os.getenv('APP_SERVER_PORT', '8080')
        self.web_server_port = os.getenv('WEB_SERVER_PORT', '3000')

        # ë¼ì¦ˆë² ë¦¬ íŒŒì´ HTTP ì„œë²„ ì„¤ì •
        self.rpi_port = int(os.getenv('RASPBERRY_PI_PORT', '5000'))

        # ì„œë²„ URL ìƒì„±[1]
        self.app_server_url = f"http://{self.app_server_ip}:{self.app_server_port}/api"
        self.web_server_url = f"http://{self.web_server_ip}:{self.web_server_port}/api"

        self.POSE_DIR = "stored_poses"

        # MediaPipe ì´ˆê¸°í™”[2][3]
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=1,
            min_detection_confidence=0.6,
            min_tracking_confidence=0.4,
            model_complexity=0
        )

        # ìŒì„± ì¸ì‹ ì´ˆê¸°í™”[4]
        self.recognizer = sr.Recognizer()
        self.microphone = None
        self.setup_microphone()

        # ëª¨ë“œ ê´€ë¦¬ (motion/voice)
        self.mode = 'motion'
        self.voice_loop_active = False
        self.voice_stop_signal_received = False
        self.voice_loop_thread = None

        # ìƒíƒœ ê´€ë¦¬
        self.running = False
        self.measurement_lock = threading.Lock()

        # ê±°ë¦¬ ì¸¡ì • ë³€ìˆ˜[2]
        self.measuring_active = False
        self.measuring_start_time = 0
        self.measuring_duration = 5.0
        self.initial_distance = None
        self.last_print_time = 0
        self.last_send_time = 0
        self.print_interval = 1.0
        self.send_interval = 0.1

        # ì œìŠ¤ì²˜ ê°ì§€[2]
        self.gesture_buffer = deque(maxlen=3)
        self.last_gesture_time = {}
        self.gesture_cooldown = 1.5

        # Flask ì•± ì´ˆê¸°í™”
        self.flask_app = Flask(__name__)
        self.setup_flask_routes()

        self.saved_poses = self.load_poses()
        self.print_initialization_status()

    def print_initialization_status(self):
        """ì´ˆê¸°í™” ìƒíƒœ ì¶œë ¥"""
        print("=" * 60)
        print("ğŸ¤– HTTP ìŒì„± ì¤‘ì§€ ì‹ í˜¸ ì œìŠ¤ì²˜ ì¸ì‹ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ“± ì•±ì„œë²„ (ìŒì„±): {self.app_server_url}")
        print(f"ğŸŒ ì›¹ì„œë²„ (ê±°ë¦¬): {self.web_server_url}")
        print(f"ğŸ”Œ ë¼ì¦ˆë² ë¦¬íŒŒì´ HTTP ì„œë²„: í¬íŠ¸ {self.rpi_port}")
        print(f"ğŸ“ ì €ì¥ëœ í¬ì¦ˆ: {list(self.saved_poses.keys())}")
        print(f"ğŸ¤ ë§ˆì´í¬ ìƒíƒœ: {'âœ… ì¤€ë¹„ë¨' if self.microphone else 'âŒ ì˜¤ë¥˜'}")
        print("ğŸ”„ left_hand: ìŒì„± ë£¨í”„ ì‹œì‘ (HTTP /voice-stop ì‹ í˜¸ë¡œ ì¢…ë£Œ)")
        print("ğŸ“ right_hand: 5ì´ˆê°„ ê±°ë¦¬ì¸¡ì •")
        print("=" * 60)
        time.sleep(0.3)  # ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ íƒ€ì´ë° ì„ í˜¸ì‚¬í•­ ë°˜ì˜[8]

    def setup_flask_routes(self):
        """Flask HTTP ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •"""
        @self.flask_app.route('/voice-stop', methods=['POST'])
        def voice_stop():
            """ìŒì„± ì¸ì‹ ì¤‘ì§€ ì‹ í˜¸ ìˆ˜ì‹ """
            try:
                print("ğŸ“¡ HTTP ìŒì„± ì¸ì‹ ì¤‘ì§€ ì‹ í˜¸ ìˆ˜ì‹ ")
                time.sleep(0.2)  # ì¶œë ¥ ê°„ê²© ì¡°ì ˆ[8]
                self.voice_stop_signal_received = True
                self.voice_loop_active = False
                print("âœ… ìŒì„± ì¸ì‹ ì¤‘ì§€ ì‹ í˜¸ ì²˜ë¦¬ ì™„ë£Œ")
                return jsonify({"status": "success", "message": "Voice recognition stopped"}), 200
            except Exception as e:
                print(f"âŒ ìŒì„± ì¤‘ì§€ ì‹ í˜¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                return jsonify({"status": "error", "message": str(e)}), 500

        @self.flask_app.route('/status', methods=['GET'])
        def get_status():
            """í˜„ì¬ ìƒíƒœ í™•ì¸"""
            return jsonify({
                "mode": self.mode,
                "voice_loop_active": self.voice_loop_active,
                "measuring_active": self.measuring_active,
                "running": self.running
            }), 200

    def start_flask_server(self):
        """Flask ì„œë²„ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)"""
        def run_flask():
            # Flask ë¡œê·¸ ì–µì œ
            log = logging.getLogger('werkzeug')
            log.setLevel(logging.ERROR)
            self.flask_app.run(host='0.0.0.0', port=self.rpi_port, debug=False, use_reloader=False)

        flask_thread = threading.Thread(target=run_flask, daemon=True)
        flask_thread.start()
        print(f"ğŸ”Œ Flask HTTP ì„œë²„ ì‹œì‘ë¨ (í¬íŠ¸: {self.rpi_port})")
        time.sleep(0.3)

    def setup_microphone(self):
        """USB ë§ˆì´í¬ ì„¤ì •[4]"""
        try:
            mic_list = sr.Microphone.list_microphone_names()
            usb_mic_index = None

            for i, name in enumerate(mic_list):
                if name and any(keyword in name.lower() for keyword in
                               ['usb', 'composite', 'hw:2,0', 'card 2']):
                    usb_mic_index = i
                    break

            self.microphone = sr.Microphone(device_index=usb_mic_index) if usb_mic_index is not None else sr.Microphone()

            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=0.5)

        except Exception:
            self.microphone = sr.Microphone()

    def extract_landmarks(self, frame):
        """ì† ëœë“œë§ˆí¬ ì¶”ì¶œ[2]"""
        try:
            small_frame = cv2.resize(frame, (320, 240))
            rgb_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
            results = self.hands.process(rgb_frame)

            if results.multi_hand_landmarks:
                hand_landmarks = results.multi_hand_landmarks[0]
                landmarks = np.array([[lm.x * frame.shape[1], lm.y * frame.shape[0]]
                                    for lm in hand_landmarks.landmark])
                return landmarks
        except Exception:
            pass
        return None

    def calculate_distance(self, p1, p2):
        """ê±°ë¦¬ ê³„ì‚°[2]"""
        try:
            return np.linalg.norm(np.array(p1) - np.array(p2))
        except Exception:
            return 0.0

    def pose_similarity(self, pose1, pose2):
        """í¬ì¦ˆ ìœ ì‚¬ë„ ê³„ì‚°[2]"""
        try:
            if pose1 is None or pose2 is None or len(pose1) != 21:
                return float('inf')

            norm_pose1 = pose1 - pose1[0]
            norm_pose2 = pose2 - pose2[0]

            key_points = [4, 8, 12, 16, 20]
            distances = [self.calculate_distance(norm_pose1[i], norm_pose2[i])
                        for i in key_points]
            return np.mean(distances)
        except Exception:
            return float('inf')

    def recognize_gesture(self, landmarks):
        """ì œìŠ¤ì²˜ ì¸ì‹[2]"""
        if landmarks is None:
            self.gesture_buffer.append(None)
            return None

        best_match = None
        min_similarity = float('inf')

        for name, ref_pose in self.saved_poses.items():
            similarity = self.pose_similarity(ref_pose, landmarks)
            if similarity < min_similarity and similarity < 25:
                min_similarity = similarity
                best_match = name

        self.gesture_buffer.append(best_match)

        if len(self.gesture_buffer) >= 2:
            recent = list(self.gesture_buffer)[-2:]
            if all(g == best_match and g is not None for g in recent):
                return best_match

        return None

    def is_gesture_allowed(self, gesture_name):
        """ì œìŠ¤ì²˜ ì¿¨ë‹¤ìš´ í™•ì¸"""
        current_time = time.time()
        return (gesture_name not in self.last_gesture_time or
                current_time - self.last_gesture_time[gesture_name] >= self.gesture_cooldown)

    def execute_gesture(self, gesture_name):
        """ì œìŠ¤ì²˜ ì‹¤í–‰"""
        if not self.is_gesture_allowed(gesture_name):
            return

        self.last_gesture_time[gesture_name] = time.time()

        if gesture_name == "left_hand":
            print("ğŸ¤ left_hand ì œìŠ¤ì²˜ ê°ì§€ - ìŒì„± ë£¨í”„ ì‹œì‘")
            time.sleep(0.2)
            self.start_voice_loop()
        elif gesture_name == "right_hand":
            print("ğŸ“ right_hand ì œìŠ¤ì²˜ ê°ì§€ - 5ì´ˆê°„ ê±°ë¦¬ ì¸¡ì • ì‹œì‘")
            time.sleep(0.2)
            self.start_distance_measurement()

    def start_voice_loop(self):
        """ìŒì„± ì¸ì‹ ë£¨í”„ ì‹œì‘ - HTTP /voice-stop ì‹ í˜¸ê¹Œì§€ ë°˜ë³µ"""
        if self.voice_loop_active:
            print("ğŸ¤ ì´ë¯¸ ìŒì„± ë£¨í”„ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
            return

        self.mode = 'voice'
        self.voice_loop_active = True
        self.voice_stop_signal_received = False

        print("ğŸ”„ ìŒì„± ë£¨í”„ ëª¨ë“œ ì‹œì‘ - HTTP /voice-stop ì‹ í˜¸ê¹Œì§€ ë°˜ë³µ")
        time.sleep(0.3)
        self.voice_loop_thread = threading.Thread(target=self._voice_loop_thread, daemon=True)
        self.voice_loop_thread.start()

    def _voice_loop_thread(self):
        """ìŒì„± ì¸ì‹ ë£¨í”„ ìŠ¤ë ˆë“œ[4]"""
        loop_count = 0

        while self.voice_loop_active and not self.voice_stop_signal_received:
            loop_count += 1
            print(f"ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘ (ë£¨í”„ {loop_count}íšŒ)")
            time.sleep(0.2)

            try:
                with self.microphone as source:
                    print("ğŸ¤ ìŒì„± ì…ë ¥ ëŒ€ê¸° ì¤‘... (5ì´ˆ íƒ€ì„ì•„ì›ƒ)")
                    audio = self.recognizer.listen(source, timeout=10, phrase_time_limit=10)

                print("ğŸ”„ ìŒì„± ì²˜ë¦¬ ì¤‘...")
                text = self.recognizer.recognize_google(audio, language='ko-KR')
                print(f"âœ… ì¸ì‹ëœ í…ìŠ¤íŠ¸: '{text}'")
                time.sleep(0.2)

                # ì•±ì„œë²„ë¡œ ìŒì„±ì¸ì‹ ê²°ê³¼ ì „ì†¡
                self.send_voice_to_app_server(text)

            except sr.WaitTimeoutError:
                print("â° ìŒì„± ì…ë ¥ íƒ€ì„ì•„ì›ƒ - ë‹¤ì‹œ ì‹œë„")
            except sr.UnknownValueError:
                print("âŒ ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - ë‹¤ì‹œ ì‹œë„")
            except Exception as e:
                print(f"âŒ ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e} - ë‹¤ì‹œ ì‹œë„")

            # HTTP ì¤‘ì§€ ì‹ í˜¸ ì²´í¬
            if self.voice_stop_signal_received:
                print("ğŸ“¡ HTTP ìŒì„± ì¤‘ì§€ ì‹ í˜¸ í™•ì¸, ë£¨í”„ ì¢…ë£Œ")
                break

            # ë£¨í”„ ê°„ê²©
            time.sleep(1)

        # ìŒì„± ë£¨í”„ ì¢…ë£Œ ì‹œ ëª¨ì…˜ ì¸ì‹ ëª¨ë“œë¡œ ë³µê·€
        self.voice_loop_active = False
        self.mode = 'motion'
        print("ğŸ”„ ìŒì„± ë£¨í”„ ì¢…ë£Œ - ëª¨ì…˜ ì¸ì‹ ëª¨ë“œë¡œ ë³µê·€")
        time.sleep(0.3)

    def send_voice_to_app_server(self, text):
        """ìŒì„± ì¸ì‹ ê²°ê³¼ë¥¼ ì•±ì„œë²„ë¡œ ì „ì†¡[1]"""
        def send_async():
            try:
                response = requests.post(
                    f"{self.app_server_url}/voice",
                    json={
                        "recognized_text": text,
                        "timestamp": time.time(),
                        "source": "raspberry_pi",
                        "loop_mode": True
                    },
                    timeout=5
                )
                if response.status_code == 200:
                    print(f"ğŸ“¤ ì•±ì„œë²„ ì „ì†¡ ì™„ë£Œ: {text}")
                else:
                    print(f"âš ï¸ ì•±ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            except Exception as e:
                print(f"âŒ ì•±ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {e}")

        threading.Thread(target=send_async, daemon=True).start()

    def start_distance_measurement(self):
        """ê±°ë¦¬ ì¸¡ì • ì‹œì‘[2]"""
        with self.measurement_lock:
            self.measuring_active = True
            self.measuring_start_time = time.time()
            self.initial_distance = None
            self.last_print_time = 0
            self.last_send_time = 0

    def process_timed_distance_measurement(self, landmarks):
        """ì‹œê°„ ê¸°ë°˜ ê±°ë¦¬ ì¸¡ì • ì²˜ë¦¬[2]"""
        if not self.measuring_active:
            return

        current_time = time.time()
        elapsed = current_time - self.measuring_start_time

        if elapsed > self.measuring_duration:
            with self.measurement_lock:
                self.measuring_active = False
            print("ğŸ“ 5ì´ˆ ê²½ê³¼ - ê±°ë¦¬ ì¸¡ì • ì™„ë£Œ")
            time.sleep(0.2)
            return

        if landmarks is None:
            return

        try:
            with self.measurement_lock:
                thumb_tip = landmarks[4]
                index_tip = landmarks[8]
                current_distance = self.calculate_distance(thumb_tip, index_tip)

                if self.initial_distance is None:
                    self.initial_distance = current_distance
                    print(f"ğŸ“ ì´ˆê¸° ê±°ë¦¬ ì„¤ì •: {self.initial_distance:.2f}px")

                distance_diff = current_distance - self.initial_distance

                if current_time - self.last_print_time >= self.print_interval:
                    remaining_time = self.measuring_duration - elapsed
                    print(f"ğŸ“Š ì´ˆê¸°: {self.initial_distance:.2f}px | í˜„ì¬: {current_distance:.2f}px | ì°¨ì´: {distance_diff:.2f}px | ë‚¨ì€ì‹œê°„: {remaining_time:.1f}s")
                    self.last_print_time = current_time

                if current_time - self.last_send_time >= self.send_interval:
                    self.send_distance_to_web_server(distance_diff, current_distance, self.initial_distance, elapsed)
                    self.last_send_time = current_time

        except Exception as e:
            print(f"âŒ ê±°ë¦¬ ì¸¡ì • ì˜¤ë¥˜: {e}")

    def send_distance_to_web_server(self, distance_diff, current_distance, initial_distance, elapsed_time):
        """ê±°ë¦¬ ì¸¡ì • ê²°ê³¼ë¥¼ ì›¹ì„œë²„ë¡œ ì „ì†¡[1]"""
        def send_async():
            try:
                response = requests.post(
                    f"{self.web_server_url}/distance",
                    json={
                        "distance_difference": distance_diff,
                        "current_distance": current_distance,
                        "initial_distance": initial_distance,
                        "elapsed_time": elapsed_time,
                        "timestamp": time.time(),
                        "source": "raspberry_pi",
                        "unit": "pixels"
                    },
                    timeout=2
                )
                if response.status_code != 200:
                    print(f"âš ï¸ ì›¹ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            except Exception:
                pass

        threading.Thread(target=send_async, daemon=True).start()

    def load_poses(self):
        """ì €ì¥ëœ í¬ì¦ˆ ë¡œë“œ"""
        saved = {}
        if not os.path.exists(self.POSE_DIR):
            return saved

        for file in os.listdir(self.POSE_DIR):
            if file.endswith("_pose.npy") and file.startswith(("left_hand", "right_hand")):
                name = file.replace("_pose.npy", "")
                try:
                    pose = np.load(os.path.join(self.POSE_DIR, file))
                    if pose.shape == (21, 2):
                        saved[name] = pose
                except Exception:
                    pass
        return saved

    def run(self):
        """ë©”ì¸ ì‹¤í–‰ - Flask ì„œë²„ì™€ ì œìŠ¤ì²˜ ì¸ì‹ ë™ì‹œ ì‹¤í–‰[3]"""
        # Flask ì„œë²„ ì‹œì‘
        self.start_flask_server()

        # ì¹´ë©”ë¼ ì´ˆê¸°í™”[3]
        cap = cv2.VideoCapture(0)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 480)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 360)
        cap.set(cv2.CAP_PROP_FPS, 15)
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

        if not cap.isOpened():
            print("âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        self.running = True
        frame_count = 0
        current_gesture = None

        print("\nğŸ¥ HTTP ìŒì„± ì¤‘ì§€ ì‹ í˜¸ + ì œìŠ¤ì²˜ ì¸ì‹ ì‹œì‘ - Ctrl+Cë¡œ ì¢…ë£Œ")
        print("ğŸ“‹ í˜„ì¬ ëª¨ë“œ: ëª¨ì…˜ ì¸ì‹")
        time.sleep(0.3)

        try:
            while self.running:
                ret, frame = cap.read()
                if not ret:
                    break

                frame_count += 1

                # ëª¨ì…˜ ì¸ì‹ ëª¨ë“œì—ì„œë§Œ ì œìŠ¤ì²˜ ê°ì§€
                if self.mode == 'motion' and frame_count % 3 == 0:
                    landmarks = self.extract_landmarks(frame)
                    detected_gesture = self.recognize_gesture(landmarks)

                    if detected_gesture and detected_gesture != current_gesture:
                        current_gesture = detected_gesture
                        print(f"ğŸ¯ ì œìŠ¤ì²˜ ê°ì§€: {detected_gesture}")
                        time.sleep(0.2)
                        self.execute_gesture(detected_gesture)

                    # ê±°ë¦¬ ì¸¡ì • ì²˜ë¦¬
                    self.process_timed_distance_measurement(landmarks)

                    if detected_gesture is None:
                        current_gesture = None

                # ìŒì„± ëª¨ë“œ ìƒíƒœ í™•ì¸
                elif self.mode == 'voice':
                    if not self.voice_loop_active:
                        self.mode = 'motion'
                        print("ğŸ“‹ í˜„ì¬ ëª¨ë“œ: ëª¨ì…˜ ì¸ì‹")
                        time.sleep(0.2)

                time.sleep(0.01)

        except KeyboardInterrupt:
            print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            self.stop()
            cap.release()

    def stop(self):
        """ì‹œìŠ¤í…œ ì •ì§€"""
        self.running = False
        self.voice_loop_active = False
        self.voice_stop_signal_received = True

        with self.measurement_lock:
            self.measuring_active = False

        self.hands.close()
        print("ğŸ”š HTTP ìŒì„± ì¤‘ì§€ ì‹ í˜¸ + ì œìŠ¤ì²˜ ì¸ì‹ê¸° ì¢…ë£Œ")

# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    recognizer = VoiceStopGestureRecognizer()

    try:
        recognizer.run()
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
    finally:
        recognizer.stop()

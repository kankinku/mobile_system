import os
import warnings
import logging
import cv2
import time
import requests
import mediapipe as mp
import numpy as np
import threading
import speech_recognition as sr
from collections import deque

# python-dotenv ì„¤ì¹˜ í™•ì¸ ë° ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("âš ï¸ python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install python-dotenvë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
    print("ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

# í™˜ê²½ ì„¤ì • ë° ê²½ê³  ì–µì œ
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['DISPLAY'] = ''
warnings.filterwarnings('ignore')
logging.getLogger('tensorflow').setLevel(logging.ERROR)
logging.getLogger('mediapipe').setLevel(logging.ERROR)
logging.getLogger('absl').setLevel(logging.ERROR)

class TimedDistanceGestureRecognizer:
    def __init__(self):
        """
        ì‹œê°„ ê¸°ë°˜ ê±°ë¦¬ ì¸¡ì • ì œìŠ¤ì²˜ ì¸ì‹ê¸°
        - ìŒì„±ì¸ì‹ ê²°ê³¼ â†’ ì•±ì„œë²„
        - ê±°ë¦¬ì¸¡ì • ê²°ê³¼ â†’ ì›¹ì„œë²„ (ì œìŠ¤ì²˜ í’€ë ¤ë„ 5ì´ˆê°„ ìœ ì§€)
        """
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„œë²„ ì„¤ì • ì½ê¸°
        self.app_server_ip = os.getenv('APP_SERVER_IP', '192.168.1.100')
        self.web_server_ip = os.getenv('WEB_SERVER_IP', '192.168.1.101')
        self.app_server_port = os.getenv('APP_SERVER_PORT', '8080')
        self.web_server_port = os.getenv('WEB_SERVER_PORT', '3000')
        
        # ì„œë²„ URL ìƒì„±
        self.app_server_url = f"http://{self.app_server_ip}:{self.app_server_port}/api"
        self.web_server_url = f"http://{self.web_server_ip}:{self.web_server_port}/api"
        
        self.POSE_DIR = "stored_poses"
        
        # MediaPipe ì´ˆê¸°í™”
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=1,
            min_detection_confidence=0.6,
            min_tracking_confidence=0.4,
            model_complexity=0
        )
        
        # ìŒì„± ì¸ì‹ ì´ˆê¸°í™”
        self.recognizer = sr.Recognizer()
        self.microphone = None
        self.is_listening = False
        self.setup_microphone()
        
        # ìƒíƒœ ê´€ë¦¬
        self.running = False
        self.measurement_lock = threading.Lock()
        
        # ì‹œê°„ ê¸°ë°˜ ê±°ë¦¬ ì¸¡ì • ë³€ìˆ˜
        self.measuring_active = False
        self.measuring_start_time = 0
        self.measuring_duration = 5.0  # 5ì´ˆê°„ ì¸¡ì • ìœ ì§€
        self.initial_distance = None
        self.last_print_time = 0
        self.last_send_time = 0
        self.print_interval = 1.0  # 1ì´ˆ ê°„ê²© ì¶œë ¥
        self.send_interval = 0.1   # 0.1ì´ˆ ê°„ê²© ì„œë²„ ì „ì†¡
        
        # ì œìŠ¤ì²˜ ê°ì§€
        self.gesture_buffer = deque(maxlen=3)
        self.last_gesture_time = {}
        self.gesture_cooldown = 1.5
        
        self.saved_poses = self.load_poses()
        self.print_initialization_status()

    def print_initialization_status(self):
        """ì´ˆê¸°í™” ìƒíƒœ ì¶œë ¥"""
        print("=" * 60)
        print("ğŸ¤– ì‹œê°„ ê¸°ë°˜ ê±°ë¦¬ ì¸¡ì • ì œìŠ¤ì²˜ ì¸ì‹ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ“± ì•±ì„œë²„ (ìŒì„±): {self.app_server_url}")
        print(f"ğŸŒ ì›¹ì„œë²„ (ê±°ë¦¬): {self.web_server_url}")
        print(f"ğŸ“ ì €ì¥ëœ í¬ì¦ˆ: {list(self.saved_poses.keys())}")
        print(f"ğŸ¤ ë§ˆì´í¬ ìƒíƒœ: {'âœ… ì¤€ë¹„ë¨' if self.microphone else 'âŒ ì˜¤ë¥˜'}")
        print("â±ï¸ ê±°ë¦¬ ì¸¡ì •: ì œìŠ¤ì²˜ ì…ë ¥ í›„ 5ì´ˆê°„ ìœ ì§€")
        print("=" * 60)

    def setup_microphone(self):
        """USB ë§ˆì´í¬ ì„¤ì •"""
        try:
            mic_list = sr.Microphone.list_microphone_names()
            usb_mic_index = None
            
            for i, name in enumerate(mic_list):
                if name and any(keyword in name.lower() for keyword in 
                               ['usb', 'composite', 'hw:2,0', 'card 2']):
                    usb_mic_index = i
                    break
            
            self.microphone = sr.Microphone(device_index=usb_mic_index) if usb_mic_index is not None else sr.Microphone()
            
            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                
        except Exception:
            self.microphone = sr.Microphone()

    def extract_landmarks(self, frame):
        """ì† ëœë“œë§ˆí¬ ì¶”ì¶œ"""
        try:
            small_frame = cv2.resize(frame, (320, 240))
            rgb_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
            results = self.hands.process(rgb_frame)
            
            if results.multi_hand_landmarks:
                hand_landmarks = results.multi_hand_landmarks[0]
                landmarks = np.array([[lm.x * frame.shape[1], lm.y * frame.shape[0]] 
                                    for lm in hand_landmarks.landmark])
                return landmarks
        except Exception:
            pass
        return None

    def calculate_distance(self, p1, p2):
        """ê±°ë¦¬ ê³„ì‚°"""
        try:
            return np.linalg.norm(np.array(p1) - np.array(p2))
        except Exception:
            return 0.0

    def pose_similarity(self, pose1, pose2):
        """í¬ì¦ˆ ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            if pose1 is None or pose2 is None or len(pose1) != 21:
                return float('inf')
            
            norm_pose1 = pose1 - pose1[0]
            norm_pose2 = pose2 - pose2[0]
            
            key_points = [4, 8, 12, 16, 20]
            distances = [self.calculate_distance(norm_pose1[i], norm_pose2[i]) 
                        for i in key_points]
            return np.mean(distances)
        except Exception:
            return float('inf')

    def recognize_gesture(self, landmarks):
        """ì œìŠ¤ì²˜ ì¸ì‹"""
        if landmarks is None:
            self.gesture_buffer.append(None)
            return None
            
        best_match = None
        min_similarity = float('inf')
        
        for name, ref_pose in self.saved_poses.items():
            similarity = self.pose_similarity(ref_pose, landmarks)
            if similarity < min_similarity and similarity < 25:
                min_similarity = similarity
                best_match = name
        
        self.gesture_buffer.append(best_match)
        
        if len(self.gesture_buffer) >= 2:
            recent = list(self.gesture_buffer)[-2:]
            if all(g == best_match and g is not None for g in recent):
                return best_match
        
        return None

    def is_gesture_allowed(self, gesture_name):
        """ì œìŠ¤ì²˜ ì¿¨ë‹¤ìš´ í™•ì¸"""
        current_time = time.time()
        return (gesture_name not in self.last_gesture_time or
                current_time - self.last_gesture_time[gesture_name] >= self.gesture_cooldown)

    def execute_gesture(self, gesture_name):
        """ì œìŠ¤ì²˜ ì‹¤í–‰"""
        if not self.is_gesture_allowed(gesture_name):
            return
        
        self.last_gesture_time[gesture_name] = time.time()
        
        if gesture_name == "left_hand":
            print("ğŸ¤ left_hand ì œìŠ¤ì²˜ ê°ì§€ - ìŒì„±ì¸ì‹ ì‹œì‘")
            self.start_voice_recognition()
        elif gesture_name == "right_hand":
            print("ğŸ“ right_hand ì œìŠ¤ì²˜ ê°ì§€ - 5ì´ˆê°„ ê±°ë¦¬ ì¸¡ì • ì‹œì‘")
            self.start_distance_measurement()

    def start_voice_recognition(self):
        """ìŒì„±ì¸ì‹ ì‹œì‘"""
        if self.is_listening:
            return
        threading.Thread(target=self._voice_thread, daemon=True).start()

    def _voice_thread(self):
        """ìŒì„±ì¸ì‹ ìŠ¤ë ˆë“œ"""
        self.is_listening = True
        
        try:
            with self.microphone as source:
                print("ğŸ¤ ìŒì„± ì…ë ¥ ëŒ€ê¸° ì¤‘... (5ì´ˆ íƒ€ì„ì•„ì›ƒ)")
                audio = self.recognizer.listen(source, timeout=5, phrase_time_limit=10)
            
            print("ğŸ”„ ìŒì„± ì²˜ë¦¬ ì¤‘...")
            text = self.recognizer.recognize_google(audio, language='ko-KR')
            print(f"âœ… ì¸ì‹ëœ í…ìŠ¤íŠ¸: '{text}'")
            
            self.send_voice_to_app_server(text)
            
        except sr.WaitTimeoutError:
            print("â° ìŒì„± ì…ë ¥ íƒ€ì„ì•„ì›ƒ")
        except sr.UnknownValueError:
            print("âŒ ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        except sr.RequestError as e:
            print(f"âŒ ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {e}")
        except Exception as e:
            print(f"âŒ ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}")
        finally:
            self.is_listening = False

    def send_voice_to_app_server(self, text):
        """ìŒì„± ì¸ì‹ ê²°ê³¼ë¥¼ ì•±ì„œë²„ë¡œ ì „ì†¡"""
        def send_async():
            try:
                response = requests.post(
                    f"{self.app_server_url}/voice",
                    json={
                        "recognized_text": text,
                        "timestamp": time.time(),
                        "source": "raspberry_pi"
                    },
                    timeout=5
                )
                if response.status_code == 200:
                    print(f"ğŸ“¤ ì•±ì„œë²„ ì „ì†¡ ì™„ë£Œ: {text}")
                else:
                    print(f"âš ï¸ ì•±ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            except Exception as e:
                print(f"âŒ ì•±ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {e}")
        
        threading.Thread(target=send_async, daemon=True).start()

    def start_distance_measurement(self):
        """ê±°ë¦¬ ì¸¡ì • ì‹œì‘ - 5ì´ˆê°„ ìœ ì§€"""
        with self.measurement_lock:
            self.measuring_active = True
            self.measuring_start_time = time.time()
            self.initial_distance = None
            self.last_print_time = 0
            self.last_send_time = 0

    def process_timed_distance_measurement(self, landmarks):
        """ì‹œê°„ ê¸°ë°˜ ê±°ë¦¬ ì¸¡ì • ì²˜ë¦¬ - ì œìŠ¤ì²˜ ìƒíƒœì™€ ë¬´ê´€í•˜ê²Œ 5ì´ˆê°„ ìœ ì§€"""
        # ì¸¡ì •ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë¦¬í„´
        if not self.measuring_active:
            return
        
        current_time = time.time()
        elapsed = current_time - self.measuring_start_time
        
        # 5ì´ˆ ê²½ê³¼ ì‹œ ì¸¡ì • ì¢…ë£Œ
        if elapsed > self.measuring_duration:
            with self.measurement_lock:
                self.measuring_active = False
            print("ğŸ“ 5ì´ˆ ê²½ê³¼ - ê±°ë¦¬ ì¸¡ì • ì™„ë£Œ")
            return
        
        # ì†ì´ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ ì´ì „ ê±°ë¦¬ê°’ ìœ ì§€í•˜ê³  ê³„ì† ì¸¡ì •
        if landmarks is None:
            return
        
        try:
            with self.measurement_lock:
                thumb_tip = landmarks[4]
                index_tip = landmarks[8]
                current_distance = self.calculate_distance(thumb_tip, index_tip)

                # ì´ˆê¸° ê±°ë¦¬ ì„¤ì • (ì²« ë²ˆì§¸ ìœ íš¨í•œ í”„ë ˆì„)
                if self.initial_distance is None:
                    self.initial_distance = current_distance
                    print(f"ğŸ“ ì´ˆê¸° ê±°ë¦¬ ì„¤ì •: {self.initial_distance:.2f}px")

                distance_diff = current_distance - self.initial_distance

                # 1ì´ˆ ê°„ê²©ìœ¼ë¡œ ì½˜ì†” ì¶œë ¥
                if current_time - self.last_print_time >= self.print_interval:
                    remaining_time = self.measuring_duration - elapsed
                    print(f"ğŸ“Š ì´ˆê¸°: {self.initial_distance:.2f}px | í˜„ì¬: {current_distance:.2f}px | ì°¨ì´: {distance_diff:.2f}px | ë‚¨ì€ì‹œê°„: {remaining_time:.1f}s")
                    self.last_print_time = current_time

                # 0.1ì´ˆ ê°„ê²©ìœ¼ë¡œ ì„œë²„ì— ì „ì†¡
                if current_time - self.last_send_time >= self.send_interval:
                    self.send_distance_to_web_server(distance_diff, current_distance, self.initial_distance, elapsed)
                    self.last_send_time = current_time

        except Exception as e:
            print(f"âŒ ê±°ë¦¬ ì¸¡ì • ì˜¤ë¥˜: {e}")

    def send_distance_to_web_server(self, distance_diff, current_distance, initial_distance, elapsed_time):
        """ê±°ë¦¬ ì¸¡ì • ê²°ê³¼ë¥¼ ì›¹ì„œë²„ë¡œ ì „ì†¡"""
        def send_async():
            try:
                response = requests.post(
                    f"{self.web_server_url}/distance",
                    json={
                        "distance_difference": distance_diff,
                        "current_distance": current_distance,
                        "initial_distance": initial_distance,
                        "elapsed_time": elapsed_time,
                        "timestamp": time.time(),
                        "source": "raspberry_pi",
                        "unit": "pixels"
                    },
                    timeout=2
                )
                if response.status_code != 200:
                    print(f"âš ï¸ ì›¹ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            except Exception:
                pass
        
        threading.Thread(target=send_async, daemon=True).start()

    def load_poses(self):
        """ì €ì¥ëœ í¬ì¦ˆ ë¡œë“œ"""
        saved = {}
        if not os.path.exists(self.POSE_DIR):
            return saved
        
        for file in os.listdir(self.POSE_DIR):
            if file.endswith("_pose.npy") and file.startswith(("left_hand", "right_hand")):
                name = file.replace("_pose.npy", "")
                try:
                    pose = np.load(os.path.join(self.POSE_DIR, file))
                    if pose.shape == (21, 2):
                        saved[name] = pose
                except Exception:
                    pass
        return saved

    def run(self):
        """ë©”ì¸ ì‹¤í–‰"""
        cap = cv2.VideoCapture(0)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 480)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 360)
        cap.set(cv2.CAP_PROP_FPS, 15)
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        if not cap.isOpened():
            print("âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        self.running = True
        frame_count = 0
        current_gesture = None
        
        print("\nğŸ¥ ì‹œê°„ ê¸°ë°˜ ê±°ë¦¬ ì¸¡ì • ì œìŠ¤ì²˜ ì¸ì‹ ì‹œì‘ - Ctrl+Cë¡œ ì¢…ë£Œ")
        print("ğŸ“‹ left_hand: ìŒì„±ì¸ì‹ â†’ ì•±ì„œë²„")
        print("ğŸ“‹ right_hand: 5ì´ˆê°„ ê±°ë¦¬ì¸¡ì • â†’ ì›¹ì„œë²„ (ì œìŠ¤ì²˜ í’€ë ¤ë„ ìœ ì§€)")
        
        try:
            while self.running:
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame_count += 1
                
                if frame_count % 3 == 0:
                    landmarks = self.extract_landmarks(frame)
                    detected_gesture = self.recognize_gesture(landmarks)
                    
                    if detected_gesture and detected_gesture != current_gesture:
                        current_gesture = detected_gesture
                        print(f"ğŸ¯ ì œìŠ¤ì²˜ ê°ì§€: {detected_gesture}")
                        self.execute_gesture(detected_gesture)
                    
                    # ì‹œê°„ ê¸°ë°˜ ê±°ë¦¬ ì¸¡ì • - ì œìŠ¤ì²˜ ìƒíƒœì™€ ë¬´ê´€í•˜ê²Œ ì²˜ë¦¬
                    self.process_timed_distance_measurement(landmarks)
                    
                    if detected_gesture is None:
                        current_gesture = None
                
                time.sleep(0.01)
                
        except KeyboardInterrupt:
            print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            self.stop()
            cap.release()

    def stop(self):
        """ì‹œìŠ¤í…œ ì •ì§€"""
        self.running = False
        with self.measurement_lock:
            self.measuring_active = False
        self.hands.close()
        print("ğŸ”š ì‹œê°„ ê¸°ë°˜ ê±°ë¦¬ ì¸¡ì • ì œìŠ¤ì²˜ ì¸ì‹ê¸° ì¢…ë£Œ")

# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    recognizer = TimedDistanceGestureRecognizer()
    
    try:
        recognizer.run()
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
    finally:
        recognizer.stop()
